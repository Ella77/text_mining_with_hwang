{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6m = pd.read_csv('../../datas_after_tokenizer/181030/6m/6m_after_prepro.csv')\n",
    "data_7m = pd.read_csv('../../datas_after_tokenizer/181030/7m/7m_after_prepro.csv')\n",
    "data_8m = pd.read_csv('../../datas_after_tokenizer/181030/8m/8m_after_prepro.csv')\n",
    "data_9m = pd.read_csv('../../datas_after_tokenizer/181030/9m/9m_after_prepro.csv')\n",
    "data_10m = pd.read_csv('../../datas_after_tokenizer/181030/10m/10m_after_prepro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    2\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    2\n",
      "7    0\n",
      "8    1\n",
      "9    0\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_6m = data_6m.sample(frac=1).reset_index(drop=True)\n",
    "df_7m = data_7m.sample(frac=1).reset_index(drop=True)\n",
    "df_8m = data_8m.sample(frac=1).reset_index(drop=True)\n",
    "df_9m = data_9m.sample(frac=1).reset_index(drop=True)\n",
    "df_10m = data_10m.sample(frac=1).reset_index(drop=True)\n",
    "print(df_6m.iloc[0:10,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_6m = df_6m.iloc[:, 1].values\n",
    "y_6m = df_6m.iloc[:, 2].values\n",
    "X_7m = df_7m.iloc[:, 1].values\n",
    "y_7m = df_7m.iloc[:, 2].values\n",
    "X_8m = df_8m.iloc[:, 1].values\n",
    "y_8m = df_8m.iloc[:, 2].values\n",
    "X_9m = df_9m.iloc[:, 1].values\n",
    "y_9m = df_9m.iloc[:, 2].values\n",
    "X_10m = df_10m.iloc[:, 1].values\n",
    "y_10m = df_10m.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text_6m, X_test_text_6m, y_train_6m, y_test_6m = train_test_split(X_6m, y_6m, test_size=0.2)\n",
    "X_train_text_7m, X_test_text_7m, y_train_7m, y_test_7m = train_test_split(X_7m, y_7m, test_size=0.2)\n",
    "X_train_text_8m, X_test_text_8m, y_train_8m, y_test_8m = train_test_split(X_8m, y_8m, test_size=0.2)\n",
    "X_train_text_9m, X_test_text_9m, y_train_9m, y_test_9m = train_test_split(X_9m, y_9m, test_size=0.2)\n",
    "X_train_text_10m, X_test_text_10m, y_train_10m, y_test_10m = train_test_split(X_10m, y_10m, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아니다 여기서는 합치는게 맞는 것 같다. numpy \n",
    "\n",
    "https://stackoverflow.com/questions/21887754/numpy-concatenate-two-arrays-vertically\n",
    "\n",
    "참고해서. 왜냐하면 tf-idf값을 추출하려면 훈련 단계별로 접근하는데 여기서 4번 훈련하면 4단계로 나뉘어져 있어서 문서 전체의 값을 뽑기 힘들어서. 만약 이 방법이 있으면 합치지 않아도 됌.\n",
    "\n",
    "http://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.W7ycdmgzZPY\n",
    "\n",
    "https://stackoverflow.com/questions/25217510/how-to-see-top-n-entries-of-term-document-matrix-after-tfidf-in-scikit-learn\n",
    "\n",
    "이 글이 좋음. 이걸로 해보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161144\n",
      "남경필 선관위 항 방문 벽보 공보물 누락 고의 대국민 사과 재발 방지책 마련 해야 오류 우회 위한 함수 추가 자유한국당 남경필 경기 지사 후보 일 오후 자신 선거 벽보 미부 착 공보물 미발 송 관련 해 재발 방지 사과 촉구 경기도 선거 관리 위원회 항 방문 했 앞서 일부 경기 지역 거리 부착 선거 벽보 기호 번 남 후보 벽보 대신 기호 번 민주당 이재명 후보 벽보 장 논란 또 우편 배달 책자 선거 공보 우편물 남 후보 공보물 후보 공보물 장 수록 됐 주장 제기 됐 남 후보 이날 저녁 경기도 수원시 영통구 경기도 선관위 방문 자리 선관위 계속 실수 상당히 고의 본다 다시 일 안 된다 남 후보 선관위 문제 대한 철저 진상 조사 통해 명백 입장 밝혀야 아직 일언반구 해명 없 같이 중대 문제 선관위 선제 잘못 된 점 대해 국민 사과 재발 방지 대한 입장 밝혀야 남 후보 특정 후보 유리 불리 일 반복 선관위 국민 소상히 설명 해 이 대해 선관위 관계자 일 간혹 고의 단순 종 사원 실수 관계자 그래도 일 안 된다고 질책 했 자꾸 남 후보 일 왜 자꾸 일 이야기 민주당 이재명 후보 캠프 앞서 입장 유감 후보 측은 선관위 이번 실수 유권자 알 권리 침해 선거 공정 치러 대한 우려 재발 방지 대책 철저히 수립 해야 자유한국당 남경필 경기 지사 후보 캠프 제공 이날 오전 화성시 동탄 신도시 아파트 주민 이재명 후보 선거 공보물 장 사진 인터넷 상 우편 온 선거 공보물 이재명 후보 공보물 장 남경필 후보 공보물 없 주장 했 네티즌 퇴근 후보 공보물 장 의도 앞서 지난 일 부천 지역 남 후보 선거 벽보 대신 이재명 후보 벽보 장 나란히 논란 일 구리시 남 후보 벽보 기호 번 바른미래당 김영환 후보 벽보 자리 이옥진 기자 조선 닷컴 바로 조선일보 구독 신청 조선일보 무단 전재 및 배포 금지 \n",
      "[0 0 2 1 0 2 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_text_6m))\n",
    "print(X_train_text_6m[0])\n",
    "print(y_train_6m[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최상의 교차 검증 점수 : 0.96\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression())\n",
    "param_grid = {\n",
    "    'logisticregression__C' : [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "#print(y_train.shape)\n",
    "grid.fit(X_train_text_6m, y_train_6m)\n",
    "grid.fit(X_train_text_7m, y_train_7m)\n",
    "grid.fit(X_train_text_8m, y_train_8m)\n",
    "grid.fit(X_train_text_9m, y_train_9m)\n",
    "grid.fit(X_train_text_10m, y_train_10m)\n",
    "print(\"최상의 교차 검증 점수 : %.2f\" %(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 테스트 점수 : 0.98\n",
      " 테스트 점수 : 0.98\n",
      " 테스트 점수 : 0.98\n",
      " 테스트 점수 : 0.98\n",
      " 테스트 점수 : 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\" 테스트 점수 : %.2f\" %(grid.score(X_test_text_6m, y_test_6m)))\n",
    "print(\" 테스트 점수 : %.2f\" %(grid.score(X_test_text_7m, y_test_7m)))\n",
    "print(\" 테스트 점수 : %.2f\" %(grid.score(X_test_text_8m, y_test_8m)))\n",
    "print(\" 테스트 점수 : %.2f\" %(grid.score(X_test_text_9m, y_test_9m)))\n",
    "print(\" 테스트 점수 : %.2f\" %(grid.score(X_test_text_10m, y_test_10m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오장동', '나카모리']\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(vector.idf_)[::-1]\n",
    "features = vector.get_feature_names()\n",
    "top_n = 2\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6월 tfidf가 가장 낮은 특성 20 개 : \n",
      " ['디야' '이민한' '판석' '무김치' '조기진' '기후대' '기후학' '기훈' '기흉' '조기완' '홍훤' '당창' '당착'\n",
      " '베다' '조기선' '조기석' '조급히' '브라더수' '긴꼬리' '무기력감']\n",
      "6월 tfidf가 가장 높은 특성 20 개 : \n",
      "  ['난민' '공증' '바오' '머크' '가구' '탁현민' '코딩' '젤라' '수경' '김광석' '수박' '5g' '타이어' '손지현'\n",
      " '복권' '정재환' '암웨이' '보노보노' '육우' '티맥스']\n"
     ]
    }
   ],
   "source": [
    "#특성 이름을 구한다.\n",
    "X_train_6m = vector.transform(X_train_text_6m)\n",
    "feature_names = np.array(vector.get_feature_names())\n",
    "max_value = X_train_6m.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "\n",
    "print(\"6월 tfidf가 가장 낮은 특성 20 개 : \\n\", feature_names[sorted_by_tfidf[:20]])\n",
    "print(\"6월 tfidf가 가장 높은 특성 20 개 : \\n \", feature_names[sorted_by_tfidf[-20:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_6m =  feature_names[sorted_by_tfidf[-3000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7월 tfidf가 가장 낮은 특성 20 개 : \n",
      " ['김응석' '비축미' '교향곡' '슈바르츠' '박애리' '독성도' '금추' '민세홍' '김이환' '전성자' '맨밥' '김효신'\n",
      " '맨더' '슈게이징' '나크' '쉰다고' '초전도' '북두' '맥키스' '금천역']\n",
      "7월 tfidf가 가장 높은 특성 20 개 : \n",
      "  ['골판지' '김광석' '송지은' '김옥빈' '전차' '난민' '수박' '가구' '타이어' '손지현' '복권' '정재환' '저글링'\n",
      " '암웨이' '루돌프' '보노보노' '티맥스' '틀니' '육우' '5g']\n",
      "7월 idf가 가장 낮은 특성 100개 \n",
      " ['기자' '금지' '배포' '무단' '위한' '추가' '오류' '우회' '함수' '전재' '뉴스' '서울' '사진' '이미지'\n",
      " '오후' '원본' '경제' '통해' '저작권자' '네이버' '한다' '지난' '위해' '바로' '채널' '구독' '대한' '함께'\n",
      " '이날' '이번' '페이스북' '된다' '진행' '한국' '제보' '열린' '제공' '방송' '대표' '가능' '시간' '관련'\n",
      " '시작' '이후' '공개' '예정' '대해' '이상' '시장' '기사' '설명' '정부' '사람' '우리' '참석' '특히'\n",
      " '모습' '한편' '최근' '확인' '문제' '미국' '연합뉴스' '관계자' 'tv' '정보' '이야기' '해야' '상황' '계획'\n",
      " '필요' '기업' '코리아' '대통령' '현재' '모두' '세계' '자신' '올해' '발표' '오늘' '가장' '영상' '언론'\n",
      " '따라' '경우' '다양' '지역' '국내' '사업' '결과' '가운데' '기술' '지난해' '지원' '개발' '적극' '공식'\n",
      " '스타' '직접']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#특성 이름을 구한다.\n",
    "X_train_7m = vector.transform(X_train_text_7m)\n",
    "feature_names = np.array(vector.get_feature_names())\n",
    "max_value = X_train_7m.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "\n",
    "print(\"7월 tfidf가 가장 낮은 특성 20 개 : \\n\", feature_names[sorted_by_tfidf[:20]])\n",
    "print(\"7월 tfidf가 가장 높은 특성 20 개 : \\n \", feature_names[sorted_by_tfidf[-20:]])\n",
    "\n",
    "sorted_by_idf = np.argsort(vector.idf_)\n",
    "print(\"7월 idf가 가장 낮은 특성 100개 \\n\", feature_names[sorted_by_idf[:100]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_7m =  feature_names[sorted_by_tfidf[-3000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8월 tfidf가 가장 낮은 특성 20 개 : \n",
      " ['학중' '손호승' '손현철' '손진호' '손준혁' '손언진' '손세빈' '손동익' '손나리' '손광업' '속증' '속선'\n",
      " '소진세' '소월리' '개척기' '소리세상' '소록도' '소래산' '호튼' '호크룩스']\n",
      "8월 tfidf가 가장 높은 특성 20 개 : \n",
      "  ['와인' '보드게임' '꼰대' '정미홍' '스팀' '손지현' '복권' '정재환' '저글링' '지부' '암웨이' '게놈' '루돌프'\n",
      " '로이킴' '보노보노' '모나미' '육우' '아보카도' '티맥스' '5g']\n",
      "8월 idf가 가장 낮은 특성 100개 \n",
      " ['기자' '금지' '배포' '무단' '위한' '추가' '오류' '우회' '함수' '전재' '뉴스' '서울' '사진' '이미지'\n",
      " '오후' '원본' '경제' '통해' '저작권자' '네이버' '한다' '지난' '위해' '바로' '채널' '구독' '대한' '함께'\n",
      " '이날' '이번' '페이스북' '된다' '진행' '한국' '제보' '열린' '제공' '방송' '대표' '가능' '시간' '관련'\n",
      " '시작' '이후' '공개' '예정' '대해' '이상' '시장' '기사' '설명' '정부' '사람' '우리' '참석' '특히'\n",
      " '모습' '한편' '최근' '확인' '문제' '미국' '연합뉴스' '관계자' 'tv' '정보' '이야기' '해야' '상황' '계획'\n",
      " '필요' '기업' '코리아' '대통령' '현재' '모두' '세계' '자신' '올해' '발표' '오늘' '가장' '영상' '언론'\n",
      " '따라' '경우' '다양' '지역' '국내' '사업' '결과' '가운데' '기술' '지난해' '지원' '개발' '적극' '공식'\n",
      " '스타' '직접']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#특성 이름을 구한다.\n",
    "X_train_8m = vector.transform(X_train_text_8m)\n",
    "feature_names = np.array(vector.get_feature_names())\n",
    "max_value = X_train_8m.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "\n",
    "print(\"8월 tfidf가 가장 낮은 특성 20 개 : \\n\", feature_names[sorted_by_tfidf[:20]])\n",
    "print(\"8월 tfidf가 가장 높은 특성 20 개 : \\n \", feature_names[sorted_by_tfidf[-20:]])\n",
    "\n",
    "sorted_by_idf = np.argsort(vector.idf_)\n",
    "print(\"8월 idf가 가장 낮은 특성 100개 \\n\", feature_names[sorted_by_idf[:100]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_8m = feature_names[sorted_by_tfidf[-3000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9월 tfidf가 가장 낮은 특성 20 개 : \n",
      " ['어벙이' '김아린' '회적' '리벤' '강재승' '천존' '천주교회' '무장면' '곽기원' '능침' '남극탐험' '천승'\n",
      " '곽봉철' '연소로' '능서면' '철호' '무염' '김시향' '청석' '박고지']\n",
      "9월 tfidf가 가장 높은 특성 20 개 : \n",
      "  ['손지현' '홍심' '복권' '신협' '정재환' '저글링' '베리' '암웨이' '게놈' '지부' '아이폰' '제대혈' '로이킴'\n",
      " '보노보노' '모나미' '아보카도' '5g' '찬미' '육우' '티맥스']\n",
      "9월 idf가 가장 낮은 특성 100개 \n",
      " ['기자' '금지' '배포' '무단' '위한' '추가' '오류' '우회' '함수' '전재' '뉴스' '서울' '사진' '이미지'\n",
      " '오후' '원본' '경제' '통해' '저작권자' '네이버' '한다' '지난' '위해' '바로' '채널' '구독' '대한' '함께'\n",
      " '이날' '이번' '페이스북' '된다' '진행' '한국' '제보' '열린' '제공' '방송' '대표' '가능' '시간' '관련'\n",
      " '시작' '이후' '공개' '예정' '대해' '이상' '시장' '기사' '설명' '정부' '사람' '우리' '참석' '특히'\n",
      " '모습' '한편' '최근' '확인' '문제' '미국' '연합뉴스' '관계자' 'tv' '정보' '이야기' '해야' '상황' '계획'\n",
      " '필요' '기업' '코리아' '대통령' '현재' '모두' '세계' '자신' '올해' '발표' '오늘' '가장' '영상' '언론'\n",
      " '따라' '경우' '다양' '지역' '국내' '사업' '결과' '가운데' '기술' '지난해' '지원' '개발' '적극' '공식'\n",
      " '스타' '직접']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#특성 이름을 구한다.\n",
    "X_train_9m = vector.transform(X_train_text_9m)\n",
    "feature_names = np.array(vector.get_feature_names())\n",
    "max_value = X_train_9m.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "\n",
    "print(\"9월 tfidf가 가장 낮은 특성 20 개 : \\n\", feature_names[sorted_by_tfidf[:20]])\n",
    "print(\"9월 tfidf가 가장 높은 특성 20 개 : \\n \", feature_names[sorted_by_tfidf[-20:]])\n",
    "\n",
    "sorted_by_idf = np.argsort(vector.idf_)\n",
    "print(\"9월 idf가 가장 낮은 특성 100개 \\n\", feature_names[sorted_by_idf[:100]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_9m = feature_names[sorted_by_tfidf[-3000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10월 tfidf가 가장 낮은 특성 20 개 : \n",
      " ['작구' '금천역' '관악역' '김춘추' '정낙균' '가톨릭의료원' '김동집' '엄기성' '조석구' '방광경' '마려워' '서호경'\n",
      " '유문부' '조기진' '김송철' '미아역' '역촌역' '관산동' '내유동' '그렇지만은']\n",
      "10월 tfidf가 가장 높은 특성 20 개 : \n",
      "  ['디트로이트' '정재환' '우표' '암웨이' '게놈' '루돌프' '지부' '아이폰' '제대혈' '로이킴' '프리다' '방귀'\n",
      " '진재영' '프링글스' '아보카도' '찬미' '육우' '티맥스' '승마' '5g']\n",
      "10월 idf가 가장 낮은 특성 100개 \n",
      " ['기자' '금지' '배포' '무단' '위한' '추가' '오류' '우회' '함수' '전재' '뉴스' '서울' '사진' '이미지'\n",
      " '오후' '원본' '경제' '통해' '저작권자' '네이버' '한다' '지난' '위해' '바로' '채널' '구독' '대한' '함께'\n",
      " '이날' '이번' '페이스북' '된다' '진행' '한국' '제보' '열린' '제공' '방송' '대표' '가능' '시간' '관련'\n",
      " '시작' '이후' '공개' '예정' '대해' '이상' '시장' '기사' '설명' '정부' '사람' '우리' '참석' '특히'\n",
      " '모습' '한편' '최근' '확인' '문제' '미국' '연합뉴스' '관계자' 'tv' '정보' '이야기' '해야' '상황' '계획'\n",
      " '필요' '기업' '코리아' '대통령' '현재' '모두' '세계' '자신' '올해' '발표' '오늘' '가장' '영상' '언론'\n",
      " '따라' '경우' '다양' '지역' '국내' '사업' '결과' '가운데' '기술' '지난해' '지원' '개발' '적극' '공식'\n",
      " '스타' '직접']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#특성 이름을 구한다.\n",
    "X_train_10m = vector.transform(X_train_text_10m)\n",
    "feature_names = np.array(vector.get_feature_names())\n",
    "max_value = X_train_10m.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "\n",
    "print(\"10월 tfidf가 가장 낮은 특성 20 개 : \\n\", feature_names[sorted_by_tfidf[:20]])\n",
    "print(\"10월 tfidf가 가장 높은 특성 20 개 : \\n \", feature_names[sorted_by_tfidf[-20:]])\n",
    "\n",
    "sorted_by_idf = np.argsort(vector.idf_)\n",
    "print(\"10월 idf가 가장 낮은 특성 100개 \\n\", feature_names[sorted_by_idf[:100]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_10m = feature_names[sorted_by_tfidf[-3000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5517\n"
     ]
    }
   ],
   "source": [
    "tf_idf_json = {}\n",
    "for data in [m_6m, m_7m, m_8m, m_9m, m_10m]:\n",
    "    for words in data:\n",
    "        if words in tf_idf_json:\n",
    "            continue\n",
    "        else:\n",
    "            tf_idf_json[words] = 1\n",
    "            \n",
    "print(len(tf_idf_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./tf_idf_json.json', 'w') as f:\n",
    "    json.dump(tf_idf_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tf_idf_json.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_i...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_.named_steps[\"logisticregression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
